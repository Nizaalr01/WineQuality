# -*- coding: utf-8 -*-
"""WineQuality_LR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5mFju13wmyyWdLBcl0lRZJy94_M-PB_
"""

# Importar librerías necesarias (solo para lectura de datos, no para modelado)
import pandas as pd
import pandas_profiling
from sklearn.model_selection import train_test_split
import seaborn as sns

"""# Descargar el df_red set


"""

# Cargar el conjunto de datos original
df_red=pd.read_csv('/content/winequality-red.csv')
df_red.shape[0]
df_red.head()

"""# Descargar el df_white set de prueba"""

# Especifica el delimitador (;) al cargar el archivo
df_white = pd.read_csv('/content/winequality-white.csv', sep=';')
df_white.shape[0]

print(df_white['quality'])

df_white.head()

"""#Exploratory df_red Analysis"""

df_red.head

df_red.isnull().sum()

df_red.info()

df_red.describe().T

pandas_profiling.ProfileReport(df_red, title="Pandas Profiling Report", explorative=True)

"""**Estadísticas del df_redset:** Todas las variables son numericas.Se encontraron 220 valores duplicados, así que los voy a eliminar para aumentar la precisión de los modelos.

**Correlaciones:** La columna alcohol y sulfatos tienen la mayor correlación con calidad mientras volatile acidity la que menos relación tiene con la anterior.
"""

df_red=df_red.drop_duplicates()

import matplotlib.pyplot as plt
sns.barplot(x=df_red['quality'], y=df_red['alcohol'])
plt.xlabel('Calidad del Vino')
plt.ylabel('Contenido de Alcohol')
plt.title('Contenido de Alcohol por Calidad del Vino')
plt.show()

"""Aquí el barplot demuestra que mientras más alta es la calidad, mayor contenido de alcohol. Comprobando la correlación del heatmap. Pero también el barplot nos ayuda a definir la función lambda para establecer un tipo de regla que permita evaluar la columna quality a una clasificación binaria."""

cantidad_mayores_a_6 = (df_red['quality'] > 6).sum()

print(f'Cantidad de valores mayores a 6 en la columna "quality": {cantidad_mayores_a_6}')

"""# Procesamiento de Datos"""

# Aplicar una función lambda a la columna 'quality' para asignar 1 si es mayor que 7, de lo contrario, 0
df_red['quality'] = df_red.quality.apply(lambda x: 1 if x > 6 else 0)

df_red['quality'].value_counts()

X = df_red.drop('quality', axis=1)
y= df_red['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=42)

print('X_train', X_train.shape)
print('X_test', X_test.shape)
print('y_train', y_train.shape)
print('y_test', y_test.shape)

"""# Regresión Logistica"""

from sklearn.linear_model import LogisticRegression
rl = LogisticRegression()
rl.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
rl_pred = rl.predict(X_test)
rl_acc = accuracy_score(rl_pred, y_test)

print('precisión del test: {:.2f}%'.format(rl_acc*100))

from sklearn.metrics import classification_report
print(classification_report(y_test, rl_pred))

from sklearn.metrics import confusion_matrix
confusion = confusion_matrix(y_test, rl_pred)

# Imprimir la matriz de confusión
print("Matriz de Confusión:")
print(confusion)

"""Pongamoslo a prueba pero ahora con el df de vino blanco

#Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
dtree_pred = dtree.predict(X_test)
dtree_acc = accuracy_score(dtree_pred, y_test)
print('precisión del test: {:.2f}%'.format(dtree_acc*100))

print(classification_report(y_test, dtree_pred))

from sklearn.metrics import confusion_matrix
confusion = confusion_matrix(y_test, dtree_pred)

# Imprimir la matriz de confusión
print("Matriz de Confusión:")
print(confusion)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rforest= RandomForestClassifier()
rforest.fit(X_train, y_train)
rforest_pred = rforest.predict(X_test)
rforest_acc = accuracy_score(rforest_pred, y_test)
print('precisión del test: {:.2f}%'.format(rforest_acc*100))

print(classification_report(y_test, rforest_pred))

"""Random Forest tiene mejor precisión que la regresión lineal y el arbol de decisión

#Pongamos a prueba los 3 modelos en df_white (nuevo training dataset)
"""

# Aplica la misma transformación a la columna "quality" en df_white
df_white['quality'] = df_white['quality'].apply(lambda x: 1 if x > 6 else 0)

print(df_white['quality'])

X_white = df_white.drop('quality', axis=1)
y_white = df_white['quality']

"""### Regresión Logistica"""

# Realiza predicciones en el conjunto de datos de vino blanco
rl_pred_white = rl.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
rl_accuracy_white = accuracy_score(y_white, rl_pred_white)
print(f'Precisión en el conjunto de datos de vino blanco (Regresión Logística): {rl_accuracy_white * 100:.2f}%')

from sklearn.metrics import confusion_matrix, f1_score
mc_rl_white= confusion_matrix(y_white, rl_pred_white)
f1_white_logistic = f1_score(y_white, rl_pred_white)

print("Matriz de Confusión:")
print(mc_rl_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Regresión Logística): {f1_white_logistic:.2f}")

"""El puntaje F1 de 0.08 indica que el modelo tiene un equilibrio entre precisión y recall, aunque parece haber un número significativo de falsos positivos y falsos negativos en comparación con los verdaderos positivos.

### Arbol de decisiones
"""

# Realiza predicciones en el conjunto de datos de vino blanco
dtree_predicciones_white = dtree.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
dtree_accuracy_white = accuracy_score(y_white, dtree_predicciones_white)
print(f'Precisión en el conjunto de datos de vino blanco (Arbol de decisiones): {dtree_accuracy_white * 100:.2f}%')

from sklearn.metrics import confusion_matrix, f1_score
mc_dtree_white= confusion_matrix(y_white, dtree_predicciones_white)
f1_white_dtree = f1_score(y_white, dtree_predicciones_white)

print("Matriz de Confusión:")
print(mc_dtree_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Regresión Logística): {f1_white_dtree =:.2f}")

"""El puntaje F1 de 0.39 indica una mejora en comparación con el modelo de Regresión Logística en términos de equilibrio entre precisión y recall. Sin embargo, aún parece haber un número significativo de falsos positivos y falsos negativos.

### Random Forest
"""

# Realiza predicciones en el conjunto de datos de vino blanco
rforest_predicciones_white = rforest.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
rforest_accuracy_white = accuracy_score(y_white, rforest_predicciones_white)
print(f'Precisión en el conjunto de datos de vino blanco (Random Forest): {rforest_accuracy_white * 100:.2f}%')

from sklearn.metrics import confusion_matrix, f1_score
mc_rforest_white= confusion_matrix(y_white, rforest_predicciones_white)
f1_white_rforest = f1_score(y_white, rforest_predicciones_white)

print("Matriz de Confusión:")
print(mc_rforest_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Random Forest): {f1_white_rforest =:.2f}")

"""El puntaje F1 de 0.25 indica que el modelo de Random Forest tiene un equilibrio entre precisión y recall, aunque el puntaje es inferior al obtenido por el modelo de Decision Tree. Esto sugiere que el Random Forest podría estar teniendo dificultades para clasificar correctamente algunos casos en el conjunto de datos de vino blanco.

# Conclusiones

Después de aplicar y entrenar tres modelos de aprendizaje automático: **Regresión Logística, Decision Tree y Random Forest**, en el conjunto de datos de vino tinto, me aventuré a probar estos modelos en un conjunto de datos de vino blanco completamente nuevo. Antes de hacerlo, tuve en cuenta que había modificado la clasificación de "quality" en el conjunto de vino tinto y apliqué la misma transformación a la columna "quality" en el conjunto de vino blanco para garantizar la coherencia en las predicciones.

Evalué primero mi modelo de Regresión Logística en el conjunto de datos de vino blanco y obtuve una precisión del 78.73%. Este resultado destaca la solidez de la Regresión Logística en la generalización a un conjunto de datos diferente, a pesar de que durante el entrenamiento el modelo con el mejor accuracy fue el Random Forest, que tuvo precisión del test del 90.69% con el conjunto de datos de vino tinto.

En general, todos los modelos demostraron la capacidad de generalizar sus predicciones al conjunto de datos de vino blanco, lo que es alentador. Sin embargo, queda margen de mejora en términos de mejorar la precisión y el puntaje F1. Ajustar los hiperparámetros de los modelos y explorar otras técnicas de preprocesamiento de datos podrían ayudar a mejorar aún más el rendimiento.
"""