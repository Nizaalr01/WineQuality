# -*- coding: utf-8 -*-
"""WineQuality_NAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z5mFju13wmyyWdLBcl0lRZJy94_M-PB_
"""

pip install pandas_profiling

# Importar librerías necesarias (solo para lectura de datos, no para modelado)
import pandas as pd
import pandas_profiling
from sklearn.model_selection import train_test_split
import seaborn as sns

"""# Descargar el df_red set


"""

# Cargar el conjunto de datos original
df_red=pd.read_csv('/content/winequality-red.csv', sep=',')
df_red.shape[0]
df_red.head()

"""# Descargar el df_white set de prueba"""

# Especifica el delimitador (;) al cargar el archivo
df_white = pd.read_csv('/content/winequality-white.csv', sep=';')
df_white.shape[0]

print(df_white['quality'])

df_white.head()

"""#Exploratory df_red Analysis"""

df_red.head

df_red.isnull().sum()

df_red.info()

df_red.describe().T

#pandas_profiling.ProfileReport(df_red, title="Pandas Profiling Report", explorative=True)

"""**Estadísticas del df_redset:** Todas las variables son numericas.Se encontraron 220 valores duplicados, así que los voy a eliminar para aumentar la precisión de los modelos.

**Correlaciones:** La columna alcohol y sulfatos tienen la mayor correlación con calidad mientras volatile acidity la que menos relación tiene con la anterior.
"""

df_red=df_red.drop_duplicates()

df_red

import matplotlib.pyplot as plt
sns.barplot(x=df_red['quality'], y=df_red['alcohol'])
plt.xlabel('Calidad del Vino')
plt.ylabel('Contenido de Alcohol')
plt.title('Contenido de Alcohol por Calidad del Vino')
plt.show()

"""Aquí el barplot demuestra que mientras más alta es la calidad, mayor contenido de alcohol. Comprobando la correlación del heatmap. Pero también el barplot nos ayuda a definir la función lambda para establecer un tipo de regla que permita evaluar la columna quality a una clasificación binaria."""

cantidad_mayores_a_6 = (df_red['quality'] > 6).sum()

print(f'Cantidad de valores mayores a 6 en la columna "quality": {cantidad_mayores_a_6}')

"""# Procesamiento de Datos"""

# Aplicar una función lambda a la columna 'quality' para asignar 1 si es mayor que 7, de lo contrario, 0
df_red['quality'] = df_red.quality.apply(lambda x: 1 if x > 6 else 0)

df_red['quality'].value_counts()

"""hay 184 de "buena calidad" y 1175 de "mala calidad"

Ahora se prepara el dataset para su respectivo entrenamiento, quitando la columna de quality. Y un test split de 30% test y y 70% train.
"""

X = df_red.drop('quality', axis=1)
y= df_red['quality']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=42)

print('X_train', X_train.shape)
print('X_test', X_test.shape)
print('y_train', y_train.shape)
print('y_test', y_test.shape)

"""# Regresión Logistica"""

from sklearn.linear_model import LogisticRegression
rl = LogisticRegression()
rl.fit(X_train, y_train)

from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
rl_pred = rl.predict(X_test)
rl_acc = accuracy_score(rl_pred, y_test)
print('precisión del test: {:.2f}%'.format(rl_acc*100))
print(classification_report(y_test, rl_pred))

"""Accuracy: 89.46"""

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Define una cuadrícula de hiperparámetros para buscar
param_grid = {
    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Parámetro de regularización
    'penalty': ['l1', 'l2'],  # Tipo de regularización
}

# Crea un modelo de Regresión Logística
rl = LogisticRegression(solver='liblinear', tol=0.001, max_iter=1000)


# Realiza una búsqueda de hiperparámetros utilizando validación cruzada
grid_search = GridSearchCV(rl, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Obtiene el mejor modelo y sus hiperparámetros
best_rl = grid_search.best_estimator_
best_params = grid_search.best_params_

# Entrena el mejor modelo en el conjunto de entrenamiento
best_rl.fit(X_train, y_train)

# Realiza predicciones en el conjunto de prueba
rl_pred = best_rl.predict(X_test)

# Calcula y muestra la precisión en el conjunto de prueba
rl_acc = accuracy_score(rl_pred, y_test)
print('Precisión en el conjunto de prueba (Regresión Logística): {:.2f}%'.format(rl_acc * 100))

"""Accuracy: 89.71%

En el código mejorado, llevé a cabo una búsqueda exhaustiva de hiperparámetros para el modelo de Regresión Logística mediante GridSearchCV. La cuadrícula de hiperparámetros definida incluyó valores para el parámetro de regularización 'C' y el tipo de regularización 'penalty'. Posteriormente, configuré el modelo de Regresión Logística con valores específicos de hiperparámetros, como el solucionador 'liblinear', la tolerancia y el número máximo de iteraciones. Luego, empleé GridSearchCV para encontrar la combinación óptima de hiperparámetros mediante validación cruzada en 5 divisiones, utilizando 'accuracy' como métrica de evaluación. Una vez encontrado el mejor modelo, lo entrené en el conjunto de entrenamiento y realicé predicciones en el conjunto de prueba. Finalmente, calculé y presenté la precisión en el conjunto de prueba

#Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier

dtree = DecisionTreeClassifier()
dtree.fit(X_train, y_train)
dtree_pred = dtree.predict(X_test)
dtree_acc = accuracy_score(dtree_pred, y_test)
print('precisión del test: {:.2f}%'.format(dtree_acc*100))

"""Accuracy:82.35%"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Definir una cuadrícula de hiperparámetros para buscar
param_grid = {
    'criterion': ['gini', 'entropy'],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Crear un modelo Decision Tree con una semilla aleatoria
dtree = DecisionTreeClassifier(random_state=42)

# Realizar una búsqueda de hiperparámetros utilizando validación cruzada
grid_search = GridSearchCV(dtree, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Obtener el mejor modelo y sus hiperparámetros
best_dtree = grid_search.best_estimator_
best_params = grid_search.best_params_

# Entrenar el mejor modelo en el conjunto de entrenamiento
best_dtree.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
dtree_pred = best_dtree.predict(X_test)

# Calcular la precisión
dtree_acc = accuracy_score(dtree_pred, y_test)
print('Precisión del conjunto de prueba: {:.2f}%'.format(dtree_acc*100))

# Otras métricas y visualización
print(classification_report(y_test, dtree_pred))
confusion = confusion_matrix(y_test, dtree_pred)
print("Matriz de Confusión:")
print(confusion)

"""Precisión: 85.78%

En el código mejorado para el modelo Decision Tree, realicé ajustes significativos para optimizar su rendimiento. Implementé una búsqueda de hiperparámetros utilizando GridSearchCV, lo que me permitió encontrar la combinación óptima de valores de hiperparámetros, incluyendo el criterio de división, la profundidad máxima del árbol, el número mínimo de muestras para dividir un nodo y el número mínimo de muestras en un nodo hoja. Esta búsqueda exhaustiva ayudó a maximizar la precisión del modelo en la clasificación de la calidad del vino. Además, calculé y presenté métricas adicionales, como la matriz de confusión y el informe de clasificación

# Random Forest
"""

from sklearn.ensemble import RandomForestClassifier
#rforest= RandomForestClassifier()
#rforest.fit(X_train, y_train)
#rforest_pred = rforest.predict(X_test)
#rforest_acc = accuracy_score(rforest_pred, y_test)
#print('precisión del test: {:.2f}%'.format(rforest_acc*100))

"""Accuracy: 90.69%"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Definir una cuadrícula de hiperparámetros para buscar
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Crear un modelo Random Forest con una semilla aleatoria
rforest = RandomForestClassifier(random_state=42)

# Realizar una búsqueda de hiperparámetros utilizando validación cruzada
grid_search = GridSearchCV(rforest, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Obtener el mejor modelo y sus hiperparámetros
best_rforest = grid_search.best_estimator_
best_params = grid_search.best_params_

# Entrenar el mejor modelo en el conjunto de entrenamiento
best_rforest.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
rforest_pred = best_rforest.predict(X_test)

# Calcular la precisión
rforest_acc = accuracy_score(rforest_pred, y_test)
print('Precisión del conjunto de prueba: {:.2f}%'.format(rforest_acc*100))

# Otras métricas y visualización
print(classification_report(y_test, rforest_pred))
confusion = confusion_matrix(y_test, rforest_pred)
print("Matriz de Confusión:")
print(confusion)

# Visualización de la importancia de las características
feature_importances = best_rforest.feature_importances_

"""Accuracy: 90.93% En el código mejorado, agregué una búsqueda de hiperparámetros utilizando GridSearchCV para encontrar la combinación óptima de valores de hiperparámetros que mejoren la precisión del modelo Random Forest. También calculé y presenté métricas adicionales, como la matriz de confusión y el informe de clasificación, para obtener una evaluación más completa del rendimiento del modelo. Además, incorporé la visualización de la importancia de las características, lo que permite identificar qué atributos influyen más en las predicciones del modelo.

#Pongamos a prueba los 3 modelos en df_white (nuevo training dataset)

Después de aplicar y entrenar tres modelos de aprendizaje automático: **Regresión Logística, Decision Tree y Random Forest**, en el conjunto de datos de vino tinto, me aventuré a probar estos modelos en un conjunto de datos de vino blanco completamente nuevo. Antes de hacerlo, tuve en cuenta que había modificado la clasificación de "quality" en el conjunto de vino tinto y apliqué la misma transformación a la columna "quality" en el conjunto de vino blanco para garantizar la coherencia en las predicciones.
"""

# Aplica la misma transformación a la columna "quality" en df_white
df_white['quality'] = df_white['quality'].apply(lambda x: 1 if x > 6 else 0)

print(df_white['quality'])

X_white = df_white.drop('quality', axis=1)
y_white = df_white['quality']

"""### Regresión Logistica"""

# Realiza predicciones en el conjunto de datos de vino blanco utilizando el modelo de Regresión Logística
rl_pred_white = best_rl.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
rl_accuracy_white = accuracy_score(y_white, rl_pred_white)
print(f'Precisión en el conjunto de datos de vino blanco (Regresión Logística): {rl_accuracy_white * 100:.2f}%')

"""Precisión en el conjunto de datos de vino blanco (Regresión Logística): 78.83%"""

from sklearn.metrics import confusion_matrix, f1_score
mc_rl_white= confusion_matrix(y_white, rl_pred_white)
f1_white_logistic = f1_score(y_white, rl_pred_white)

print("Matriz de Confusión:")
print(mc_rl_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Regresión Logística): {f1_white_logistic:.2f}")

"""F1: 0.13

### Arbol de decisiones
"""

# Realiza predicciones en el conjunto de datos de vino blanco utilizando el modelo de Decision Tree
dtree_pred_white = best_dtree.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
dtree_accuracy_white = accuracy_score(y_white, dtree_pred_white)
print(f'Precisión en el conjunto de datos de vino blanco (Decision Tree): {dtree_accuracy_white * 100:.2f}%')

"""Precisión en el conjunto de datos de vino blanco (Arbol de decisiones): 76.85%"""

from sklearn.metrics import confusion_matrix, f1_score
mc_dt_white= confusion_matrix(y_white, dtree_pred_white)
f1_white_dt = f1_score(y_white, dtree_pred_white)

print("Matriz de Confusión:")
print(mc_dt_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Regresión Logística): {f1_white_dt:.2f}")

"""F1: 0.26

### Random Forest
"""

# Realizar predicciones en el conjunto de datos de vino blanco
rforest_pred_white= best_rforest.predict(X_white)

# Calcula la precisión en el conjunto de datos de vino blanco
rforest_accuracy_white = accuracy_score(y_white, rforest_pred_white)
print(f'Precisión en el conjunto de datos de vino blanco (Random Forest): {rforest_accuracy_white * 100:.2f}%')

"""Precisión en el conjunto de datos de vino blanco (Random Forest):78.26%

"""

from sklearn.metrics import confusion_matrix, f1_score
mc_rf_white= confusion_matrix(y_white, rforest_pred_white)
f1_white_rf = f1_score(y_white, rforest_pred_white)

print("Matriz de Confusión:")
print(mc_rf_white)

print(f"Puntaje F1 en el conjunto de datos de vino blanco (Regresión Logística): {f1_white_rf:.2f}")

"""F1: 0.09

# Conclusiones
"""